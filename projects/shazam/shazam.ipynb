{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\naudio fingerprinting\\n    temporally localized\\n    translation-invariant\\n    robust to noise\\n    sufficiently entropic\\n\\nROBUST CONSTELLATIONS\\n    GSM(Global Sequence Matching)\\n\\nhttps://www.toptal.com/algorithms/shazam-it-music-processing-fingerprinting-and-recognition\\n\\nwe settled on spectrogram peaks, due to their robustness in the presence of noise and approximate linear superposability\\n\\na time-frequency point is a candidate peak if it has a higher energy content than all its neighbors in a region centered around the point\\n\\nhttps://towardsdatascience.com/learning-from-audio-spectrograms-37df29dba98c    \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "audio fingerprinting\n",
    "    temporally localized\n",
    "    translation-invariant\n",
    "    robust to noise\n",
    "    sufficiently entropic\n",
    "\n",
    "ROBUST CONSTELLATIONS\n",
    "    GSM(Global Sequence Matching)\n",
    "\n",
    "https://www.toptal.com/algorithms/shazam-it-music-processing-fingerprinting-and-recognition\n",
    "\n",
    "we settled on spectrogram peaks, due to their robustness in the presence of noise and approximate linear superposability\n",
    "\n",
    "a time-frequency point is a candidate peak if it has a higher energy content than all its neighbors in a region centered around the point\n",
    "\n",
    "https://towardsdatascience.com/learning-from-audio-spectrograms-37df29dba98c    \n",
    "\n",
    "https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/audio_preprocessing_tutorial.ipynb\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='./example.wav'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open example.mp3 and save as .wav\n",
    "# https://stackoverflow.com/questions/3049572/how-to-convert-mp3-to-wav-in-python\n",
    "\n",
    "from pydub import AudioSegment\n",
    "sound = AudioSegment.from_mp3(\"./example.mp3\")\n",
    "sound.export(\"./example.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of channels = 2\n"
     ]
    }
   ],
   "source": [
    "# view spectogram of wav file\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "# read wav file\n",
    "samplerate, data = wavfile.read('./example.wav')\n",
    "print(f\"number of channels = {data.shape[1]}\")\n",
    "\n",
    "length = data.shape[0] / samplerate\n",
    "print(f\"length = {length}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m time \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0.\u001b[39m, length, data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mplot(time, data[:, \u001b[39m0\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLeft channel\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mplot(time, data[:, \u001b[39m1\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRight channel\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'length' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "time = np.linspace(0., length, data.shape[0])\n",
    "plt.plot(time, data[:, 0], label=\"Left channel\")\n",
    "plt.plot(time, data[:, 1], label=\"Right channel\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
